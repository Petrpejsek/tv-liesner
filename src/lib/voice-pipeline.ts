// Voice Generation Pipeline - ElevenLabs Integration with Segmentation
import { generateVoice, saveAudioFile } from './elevenlabs';
import path from 'path';
import fs from 'fs/promises';
import { exec } from 'child_process';
import { promisify } from 'util';

const execAsync = promisify(exec);

/**
 * Vyƒçist√≠ text p≈ôed odesl√°n√≠m do ElevenLabs
 * - odstran√≠ markdown (**bold**, atd.)
 * - odstran√≠ meta info jako HOOK (0-3 seconds...)
 * - o≈ô√≠zne whitespace
 */
function cleanVoiceText(input: string): string {
  return input
    .replace(/^#{1,3}.*?\n/gm, '')            // Remove headers like ### HOOK
    .replace(/\*\*(.*?)\*\*/g, '$1')          // Remove bold markers
    .replace(/\(.*?\d+\s*seconds.*?\)/gi, '') // Remove (0‚Äì3 seconds...)
    .replace(/\b(HOOK|PROBLEM|SOLUTION|BENEFITS|CALL TO ACTION)\b/gi, '') // Remove meta labels
    .replace(/\n+/g, ' ')                     // Collapse newlines
    .replace(/\s{2,}/g, ' ')                  // Remove extra spaces
    .trim();
}

/**
 * Odhadne d√©lku audio na z√°kladƒõ poƒçtu slov a speaking rate
 */
function estimateDuration(text: string, speakingRate = 0.9): number {
  const words = text.split(/\s+/).length;
  // ‚úÖ Kalibrov√°no podle re√°ln√Ωch mƒõ≈ôen√≠ ElevenLabs (~3.5 wps p≈ôi normal speaking_rate)
  const baseWPS = 3.5; // re√°ln√° rychlost ElevenLabs
  const wordsPerSecond = baseWPS * (speakingRate || 1);
  return words / wordsPerSecond;
}

/**
 * Zkr√°t√≠ text aby se ve≈°el do zadan√© d√©lky
 */
function truncateTextToDuration(text: string, maxDuration: number, speakingRate = 0.9): string {
  // ‚úÖ Kalibrov√°no podle re√°ln√Ωch mƒõ≈ôen√≠ ElevenLabs (~3.5 wps p≈ôi normal speaking_rate)
  const baseWPS = 3.5; // re√°ln√° rychlost ElevenLabs
  const wordsPerSecond = baseWPS * (speakingRate || 1);
  const maxWords = Math.floor(maxDuration * wordsPerSecond);
  return text.split(/\s+/).slice(0, maxWords).join(' ');
}

/**
 * Sluƒçuje audio segmenty do jednoho fin√°ln√≠ho souboru pomoc√≠ FFmpeg
 */
async function mergeAudioSegments(
  segments: VoiceSegment[],
  pipelineId: string,
  targetDuration: number
): Promise<string> {
  console.log('üé¨ Spou≈°t√≠m sluƒçov√°n√≠ audio segment≈Ø...');
  
  // üîµ DEBUG: Preparing final merge...
  console.log("üîµ DEBUG: Preparing final merge...");
  console.log(`Files for merge: ${segments.length}`);
  segments.forEach((f, i) => console.log(`Merge file #${i+1}: ${f.audioFilePath}`));

  if (!segments || segments.length === 0) {
    throw new Error("‚ùå CRITICAL: No audio files received for merge!");
  }
  
  console.log('üîç MERGE FUNC DEBUG - segments:', segments.length);
  console.log('üîç MERGE FUNC DEBUG - pipelineId:', pipelineId);
  console.log('üîç MERGE FUNC DEBUG - targetDuration:', targetDuration);
  console.log('üîç MERGE FUNC DEBUG - segments paths:', segments.map(s => s.audioFilePath));
  
  if (segments.length === 0) {
    throw new Error('‚ùå ≈Ω√°dn√© segmenty k sluƒçov√°n√≠');
  }
  
  try {
    const uploadsDir = path.join(process.cwd(), 'public', 'uploads');
    const finalFileName = `final_audio_${pipelineId}.mp3`;
    const finalFilePath = path.join(uploadsDir, finalFileName);
    
    // Pokud je jen jeden segment, zkop√≠ruj ho jako fin√°ln√≠ s audio padding
    if (segments.length === 1) {
      const sourceFile = path.join(process.cwd(), 'public', segments[0].audioFilePath.replace(/^\//, ''));
      
      // ‚úÖ Zkontroluj d√©lku jednho segmentu a p≈ô√≠padnƒõ p≈ôidej padding
      const ffprobeCommand = `ffprobe -v quiet -show_entries format=duration -of csv=p=0 "${sourceFile}"`;
      const { stdout } = await execAsync(ffprobeCommand);
      const segmentDuration = parseFloat(stdout.trim());
      
      console.log(`üéµ Single segment duration: ${segmentDuration.toFixed(2)}s (target: ${targetDuration}s)`);
      
      if (segmentDuration < targetDuration - 0.5) {
        // P≈ôidej padding na p≈ôesn√Ω targetTime
        const silenceDuration = targetDuration - segmentDuration;
        console.log(`üîá P≈ôid√°v√°m ${silenceDuration.toFixed(2)}s ticha na konec jednho segmentu...`);
        
        const paddingCommand = `ffmpeg -i "${sourceFile}" -af "apad=pad_dur=${silenceDuration}" -y "${finalFilePath}"`;
        await execAsync(paddingCommand);
      } else {
        // Jen zkop√≠ruj bez padding
        await fs.copyFile(sourceFile, finalFilePath);
      }
      
      console.log('‚úÖ Jeden segment zpracov√°n jako fin√°ln√≠ audio');
      return `/uploads/${finalFileName}`;
    }
    
    // üé¨ NOV√ù WAV-BASED MERGE FLOW podle instrukc√≠
    console.log('üé¨ Vytv√°≈ô√≠m nov√Ω WAV-based merge flow...');
    
    // a) Ka≈æd√Ω segment MP3 ‚Üí doƒçasn√Ω WAV
    const wavSegments: string[] = [];
    console.log('üîÑ Konvertuji MP3 segmenty na WAV...');
    
    for (let i = 0; i < segments.length; i++) {
      const segment = segments[i];
      const sourceFile = path.join(process.cwd(), 'public', segment.audioFilePath.replace(/^\//, ''));
      const wavFileName = `segment_${i + 1}_${pipelineId}.wav`;
      const wavFilePath = path.join(uploadsDir, wavFileName);
      
      console.log(`üîÑ Konvertuji segment ${i + 1}/${segments.length}: ${segment.audioFilePath} ‚Üí WAV`);
      
      // P≈ôeveƒè MP3 na WAV s normalizovan√Ωmi parametry
      const convertCommand = `ffmpeg -y -i "${sourceFile}" -ar 44100 -ac 2 "${wavFilePath}"`;
      
      try {
        const { stdout, stderr } = await execAsync(convertCommand);
        if (stderr) console.log(`‚ö†Ô∏è Convert stderr ${i + 1}:`, stderr);
        wavSegments.push(wavFilePath);
        console.log(`‚úÖ Segment ${i + 1} p≈ôeveden na WAV`);
      } catch (convertError) {
        console.error(`‚ùå Chyba p≈ôi konverzi segmentu ${i + 1}:`, convertError);
        throw new Error(`MP3 to WAV conversion failed for segment ${i + 1}: ${convertError.message}`);
      }
    }
    
    // b) Vytvo≈ô seznam WAV segment≈Ø v concat_list_wav.txt
    const wavConcatListPath = path.join(uploadsDir, `concat_list_wav_${pipelineId}.txt`);
    const wavConcatContent = wavSegments.map(wavPath => `file '${wavPath}'`).join('\n');
    
    await fs.writeFile(wavConcatListPath, wavConcatContent);
    console.log('üìã Seznam WAV soubor≈Ø pro concat vytvo≈ôen');
    
    // c) Slouƒç WAV segmenty do merged.wav (bez reenk√≥dov√°n√≠)
    const mergedWavPath = path.join(uploadsDir, `merged_${pipelineId}.wav`);
    const mergeWavCommand = `ffmpeg -f concat -safe 0 -i "${wavConcatListPath}" -c copy -y "${mergedWavPath}"`;
    
    console.log('üéµ Sluƒçuji WAV segmenty bez reenk√≥dov√°n√≠...');
    console.log('üéµ WAV merge command:', mergeWavCommand);
    
    try {
      const { stdout, stderr } = await execAsync(mergeWavCommand);
      console.log('‚úÖ WAV merge stdout:', stdout);
      if (stderr) console.log('‚ö†Ô∏è WAV merge stderr:', stderr);
    } catch (mergeError) {
      console.error('‚ùå WAV merge error:', mergeError);
      throw new Error(`WAV merge failed: ${mergeError.message}`);
    }
    
    // d) Reenk√≥duj merged.wav do MP3 (nov√© validn√≠ frame headers)
    console.log('üéµ Reenk√≥duji merged WAV do fin√°ln√≠ho MP3...');
    const reencodeCommand = `ffmpeg -y -i "${mergedWavPath}" -codec:a libmp3lame -q:a 2 "${finalFilePath}"`;
    
    try {
      const { stdout, stderr } = await execAsync(reencodeCommand);
      console.log('‚úÖ MP3 reencode stdout:', stdout);
      if (stderr) console.log('‚ö†Ô∏è MP3 reencode stderr:', stderr);
      console.log('‚úÖ WAV √∫spƒõ≈°nƒõ reenk√≥dov√°no do MP3');
    } catch (reencodeError) {
      console.error('‚ùå MP3 reencode error:', reencodeError);
      throw new Error(`WAV to MP3 reencode failed: ${reencodeError.message}`);
    }
    
    // Vyƒçisti doƒçasn√© soubory
    console.log('üßπ ƒåist√≠m doƒçasn√© WAV soubory...');
    const filesToCleanup = [...wavSegments, wavConcatListPath, mergedWavPath];
    
    for (const fileToClean of filesToCleanup) {
      try {
        await fs.unlink(fileToClean);
      } catch (unlinkError) {
        console.warn(`‚ö†Ô∏è Nelze smazat doƒçasn√Ω soubor ${fileToClean}:`, unlinkError.message);
      }
    }
    
    // Ovƒõ≈ô d√©lku v√Ωsledn√©ho audio
    const ffprobeCommand = `ffprobe -v quiet -show_entries format=duration -of csv=p=0 "${finalFilePath}"`;
    const { stdout } = await execAsync(ffprobeCommand);
    const actualDuration = parseFloat(stdout.trim());
    
    console.log(`üéµ Merged audio d√©lka: ${actualDuration.toFixed(2)}s (target: ${targetDuration}s)`);
    
    // e) Pokud je pot≈ôeba target_time ‚Üí truncate A≈Ω NA KONCI (podle instrukc√≠)
    console.log(`üéØ Kontroluji d√©lku fin√°ln√≠ho MP3: ${actualDuration.toFixed(2)}s vs target ${targetDuration}s`);
    
    if (actualDuration > targetDuration + 0.1) {
      // Truncate na p≈ôesn√Ω target_time
      console.log(`‚úÇÔ∏è APLIKUJI TARGET TRUNCATION: Cutting ${actualDuration.toFixed(2)}s ‚Üí ${targetDuration}s`);
      
      const truncatedFilePath = path.join(uploadsDir, `truncated_${finalFileName}`);
      const truncateCommand = `ffmpeg -y -t ${targetDuration} -i "${finalFilePath}" "${truncatedFilePath}"`;
      
      try {
        await execAsync(truncateCommand);
        await fs.rename(truncatedFilePath, finalFilePath); // Replace s truncated verz√≠
        console.log(`‚úÖ Audio √∫spƒõ≈°nƒõ truncated na ${targetDuration}s`);
      } catch (truncateError) {
        console.error(`‚ùå Chyba p≈ôi truncation:`, truncateError);
        throw new Error(`Target truncation failed: ${truncateError.message}`);
      }
    } else if (actualDuration < targetDuration - 0.5) {
      // Jen pokud je v√Ωraznƒõ krat≈°√≠, p≈ôidej ticho
      const silenceDuration = targetDuration - actualDuration;
      const tempFilePath = path.join(uploadsDir, `temp_${finalFileName}`);
      
      console.log(`üîá P≈ôid√°v√°m ${silenceDuration.toFixed(2)}s ticha na konec...`);
      
      const paddingCommand = `ffmpeg -i "${finalFilePath}" -af "apad=pad_dur=${silenceDuration}" -y "${tempFilePath}"`;
      
      await execAsync(paddingCommand);
      await fs.rename(tempFilePath, finalFilePath);
      
      console.log('‚úÖ Ticho p≈ôid√°no na konec audio');
    } else {
      console.log(`‚úÖ Audio d√©lka v po≈ô√°dku: ${actualDuration.toFixed(2)}s (target: ${targetDuration}s)`);
    }
    
    // ‚úÖ Fin√°ln√≠ validace d√©lky merged audio
    const finalFFprobeCommand = `ffprobe -v quiet -show_entries format=duration -of csv=p=0 "${finalFilePath}"`;
    const { stdout: finalStdout } = await execAsync(finalFFprobeCommand);
    const finalActualDuration = parseFloat(finalStdout.trim());
    
    console.log(`üéØ FINAL VALIDATION: audio=${finalActualDuration.toFixed(2)}s, target=${targetDuration}s, diff=${Math.abs(finalActualDuration - targetDuration).toFixed(2)}s`);
    
    // ‚úÖ KONTROLA FIN√ÅLN√ç D√âLKY
    console.log(`‚úÖ Final merged audio created. Duration: ${finalActualDuration.toFixed(2)}s`);
    if (finalActualDuration < targetDuration * 0.8) {
      throw new Error(`‚ùå CRITICAL: Final audio only ${finalActualDuration.toFixed(2)}s but expected ${targetDuration}s!`);
    }
    
    // ‚úÖ Truncation u≈æ byla aplikov√°na v nov√©m WAV flow v√Ω≈°e
    console.log(`‚úÖ Audio duration po nov√©m WAV flow: ${finalActualDuration.toFixed(2)}s vs ${targetDuration}s`)
    
    console.log('‚úÖ Audio segmenty √∫spƒõ≈°nƒõ slouƒçeny');
    return `/uploads/${finalFileName}`;
    
  } catch (error) {
    console.error('‚ùå Chyba p≈ôi sluƒçov√°n√≠ audio segment≈Ø:', error);
    throw new Error(`FFmpeg merge failed: ${error.message}`);
  }
}

export interface VoiceGenerationResult {
  segments: VoiceSegment[];
  totalDuration: number;
  targetTime: number;
  speakingRate: number;
  finalAudioPath?: string;
  finalAudioDuration?: number;
}

export interface VoiceSegment {
  id: string;
  text: string;
  audioFilePath: string;
  startTime: number;
  endTime: number;
  duration: number;
}

export interface ApiKeys {
  elevenlabs?: string;
  voiceId?: string;
}

export async function generateVoiceFromScript(
  videoScript: string,
  timeline: any,
  apiKeys: ApiKeys,
  targetDuration: number, // ‚úÖ Unifikov√°no - v≈°ude targetDuration
  pipelineId?: string // ‚úÖ P≈ôid√°no pro sluƒçov√°n√≠ segment≈Ø
): Promise<VoiceGenerationResult> {
  console.log('üó£Ô∏è Spou≈°t√≠m ElevenLabs Voice Generation s segmentac√≠...');
  
  // ‚úÖ Debug logov√°n√≠ API kl√≠ƒç≈Ø
  console.log('üêõ Voice Pipeline DEBUG - API kl√≠ƒçe:');
  console.log('üîë apiKeys received:', Object.keys(apiKeys));
  console.log('üîë voiceId value:', apiKeys.voiceId);
  console.log('üîë elevenlabs starts with:', apiKeys.elevenlabs ? `${apiKeys.elevenlabs.substring(0, 10)}...` : 'MISSING');
  
  // ‚úÖ Debug logov√°n√≠ targetDuration
  console.log(`üéØ Target duration: ${targetDuration} seconds`);
  
  // ‚úÖ Validace targetDuration (ochrana proti nevalidn√≠m hodnot√°m)
  if (!targetDuration || targetDuration < 3 || targetDuration > 60) {
    throw new Error(`‚ùå Invalid targetDuration: ${targetDuration} (must be 3‚Äì60 seconds)`);
  }
  
  // Validace API kl√≠ƒç≈Ø
  if (!apiKeys.elevenlabs) {
    console.error('‚ùå ElevenLabs API kl√≠ƒç chyb√≠!');
    throw new Error('ElevenLabs API kl√≠ƒç nen√≠ nastaven v environment variables');
  }
  
  if (!apiKeys.voiceId) {
    console.error('‚ùå Voice ID chyb√≠!');
    throw new Error('Voice ID nen√≠ nastaven v environment variables');
  }

  console.log(`üéôÔ∏è Pou≈æ√≠v√°m Voice ID: ${apiKeys.voiceId}`);
  
  try {
    // Extrakce timeline segments - STRICT, NO FALLBACKS
    let timelineSegments = [];
    
    if (!timeline || !timeline.segments || !Array.isArray(timeline.segments)) {
      throw new Error(`‚ùå PIPELINE STOPPED: Invalid timeline data. Timeline must contain segments array. Received: ${typeof timeline}`);
    }
    
    if (timeline.segments.length < 2) {
      throw new Error(`‚ùå PIPELINE STOPPED: Timeline has insufficient segments (${timeline.segments.length} < 2). AI must generate at least 2 segments.`);
    }
    
    timelineSegments = timeline.segments;
    
    // üü¢ DEBUG: Preparing ElevenLabs payload...
    console.log("üü¢ DEBUG: Preparing ElevenLabs payload...");
    console.log(`Total segments from Timeline: ${timelineSegments.length}`);
    timelineSegments.forEach((s: any, i: number) => {
      const text = s.voice_text || s.text || '';
      console.log(`Segment #${i+1}: "${text}" (${text.split(' ').length} words)`);
    });
    
    console.log(`üîÑ Generuji hlas pro ${timelineSegments.length} segment≈Ø z timeline`);

    // üéØ KALKULACE SPEAKING RATE
    const totalWords = timelineSegments.reduce((sum: number, seg: any) => {
      const text = seg.voice_text || seg.text || '';
      return sum + text.split(' ').filter((w: string) => w.length > 0).length;
    }, 0);
    
    const wordsPerSecond = totalWords / targetDuration;
    const expectedDuration = totalWords / 2.3; // Standardn√≠ rychlost 2.3 slov/sec
    
    console.log(`üìä Voice Stats - Total words: ${totalWords}, Expected duration: ${expectedDuration.toFixed(1)}s, Target: ${targetDuration}s`);
    
    // üéöÔ∏è ENHANCED DYNAMIC SPEAKING RATE ADJUSTMENT
    let speakingRate = 1.0;
    const durationDiff = expectedDuration - targetDuration;
    const diffPercentage = (durationDiff / targetDuration) * 100;
    
    console.log(`üìä Duration analysis: expected=${expectedDuration.toFixed(1)}s, target=${targetDuration}s, diff=${durationDiff.toFixed(1)}s (${diffPercentage.toFixed(1)}%)`);
    
    if (Math.abs(diffPercentage) <= 5) {
      // ¬±5% tolerance - perfektn√≠
      speakingRate = 1.0;
      console.log(`‚úÖ Speaking rate z≈Øst√°v√° 1.0 (optim√°ln√≠ d√©lka, rozd√≠l ${diffPercentage.toFixed(1)}%)`);
    } else if (durationDiff > 0) {
      // P≈ô√≠li≈° dlouh√© ‚Üí zrychli
      if (diffPercentage > 20) {
        speakingRate = 1.25; // V√Ωraznƒõ zrychli
      } else if (diffPercentage > 10) {
        speakingRate = 1.15; // St≈ôednƒõ zrychli
      } else {
        speakingRate = 1.05; // M√≠rnƒõ zrychli
      }
      console.log(`‚ö° Zrychluju speaking rate na ${speakingRate} (p≈ô√≠li≈° dlouh√© o ${diffPercentage.toFixed(1)}%)`);
    } else {
      // P≈ô√≠li≈° kr√°tk√© ‚Üí zpomal
      if (Math.abs(diffPercentage) > 20) {
        speakingRate = 0.85; // V√Ωraznƒõ zpomal
      } else if (Math.abs(diffPercentage) > 10) {
        speakingRate = 0.9; // St≈ôednƒõ zpomal
      } else {
        speakingRate = 0.95; // M√≠rnƒõ zpomal
      }
      console.log(`üêå Zpomaluju speaking rate na ${speakingRate} (p≈ô√≠li≈° kr√°tk√© o ${Math.abs(diffPercentage).toFixed(1)}%)`);
    }
    
    // ‚úÖ Clamp speaking rate do bezpeƒçn√Ωch mez√≠ ElevenLabs
    speakingRate = Math.max(0.8, Math.min(1.3, speakingRate));
    console.log(`üéöÔ∏è Final speaking rate: ${speakingRate} (clamped to 0.8-1.3 range)`);
    
    // ‚úÖ P≈ôedpovƒõƒè fin√°ln√≠ d√©lky s upraven√Ωm speaking rate
    const predictedDuration = expectedDuration / speakingRate;
    console.log(`üéØ Predicted final duration: ${predictedDuration.toFixed(1)}s (${((predictedDuration / targetDuration) * 100).toFixed(1)}% of target)`);
    
    if (Math.abs(predictedDuration - targetDuration) > targetDuration * 0.15) {
      console.warn(`‚ö†Ô∏è Predicted duration ${predictedDuration.toFixed(1)}s still differs significantly from target ${targetDuration}s`);
    }

    // Voice settings s dynamic speaking rate
    const voiceSettings = {
      stability: 0.7,
      similarity_boost: 0.8,
      style: 0.2,
      use_speaker_boost: true,
      speaking_rate: speakingRate
    };

    // üîÑ SEGMENTOVAN√â GENEROV√ÅN√ç
    const generatedSegments: VoiceSegment[] = [];
    let currentTime = 0;
    
    // ‚úÖ KONTROLA P≈òED ELEVENLABS
    if (!timelineSegments || timelineSegments.length === 0) {
      throw new Error("‚ùå CRITICAL: No segments found for ElevenLabs request!");
    }
    
    for (let i = 0; i < timelineSegments.length; i++) {
      const segment = timelineSegments[i];
      
      // ‚úÖ Vezmi ƒçist√Ω script z timeline (nikdy voice direction!)
      const segmentText = segment.text || segment.voice_text || '';
      
      if (!segmentText.trim()) {
        throw new Error(`‚ùå Empty segment text at index ${i + 1}`);
      }
      
      console.log(`üé§ Generuji segment ${i + 1}/${timelineSegments.length}: "${segmentText.substring(0, 50)}..."`);
      
      try {
        // ‚úÖ Vyƒçisti text od metadat (HOOK, sekundy, markdown, apod.)
        let textToSpeak = cleanVoiceText(segmentText);
        
        // ‚úÖ Validace ≈æe text nen√≠ pr√°zdn√Ω po ƒçi≈°tƒõn√≠
        if (!textToSpeak || textToSpeak.length < 10) {
          throw new Error("‚ùå Text too short for ElevenLabs after cleaning");
        }
        
        // ‚úÖ Kontrola, jestli se nepos√≠l√° VOICE DIRECTION
        if (/Tone:|Pace:|Emphasis:|Inflection:/.test(textToSpeak)) {
          throw new Error("‚ùå Wrong input for ElevenLabs ‚Äì VOICE DIRECTION DETECTED!");
        }
        
        // ‚úÖ Pre-check d√©lky textu v≈Øƒçi targetDuration
        const segmentTargetDuration = segment.duration || (targetDuration / timelineSegments.length);
        const estimatedDuration = estimateDuration(textToSpeak, voiceSettings.speaking_rate);
        
        // üéØ DETAILN√ç DEBUG LOGY PRO LADƒöN√ç
        const baseWPS = 3.5; // re√°ln√° rychlost ElevenLabs (stejn√© jako v estimateDuration)
        const dynamicWPS = baseWPS * (voiceSettings.speaking_rate || 1);
        console.log(`üéØ Target duration: ${segmentTargetDuration.toFixed(2)}s`);
        console.log(`üìä Expected WPS: ${dynamicWPS.toFixed(2)} (base: ${baseWPS}, rate: ${voiceSettings.speaking_rate})`);
        console.log(`üîç Segment estimation: ${estimatedDuration.toFixed(2)}s, target: ${segmentTargetDuration.toFixed(2)}s`);
        console.log(`üìä Segment ${i + 1}: target ${segmentTargetDuration.toFixed(1)}s, estimated ${estimatedDuration.toFixed(1)}s`);
        console.log(`üé¨ Max duration per segment: ${(targetDuration / timelineSegments.length).toFixed(2)}s (${targetDuration}s / ${timelineSegments.length} segments)`);
        
        // ‚úÖ Nov√° tolerantn√≠ logika (20% tolerance p≈ôed truncation)
        if (estimatedDuration > segmentTargetDuration * 1.2) {
          console.warn(`‚ö†Ô∏è Text je del≈°√≠ o ${Math.round((estimatedDuration / segmentTargetDuration - 1) * 100)}% ‚Üí zkracuji`);
          textToSpeak = truncateTextToDuration(textToSpeak, segmentTargetDuration * 1.15, voiceSettings.speaking_rate);
        } else {
          console.log(`‚úÖ Text je v toleranci (${estimatedDuration.toFixed(2)}s vs target ${segmentTargetDuration.toFixed(2)}s), ponech√°v√°m cel√Ω`);
        }
        
        console.log(`‚úÖ CLEAN TEXT FOR ELEVENLABS: ${textToSpeak}`);
        console.log(`‚è±Ô∏è Estimated duration: ${estimateDuration(textToSpeak, voiceSettings.speaking_rate).toFixed(1)}s (target ${segmentTargetDuration.toFixed(1)}s)`);
        if (estimatedDuration > segmentTargetDuration) console.log("‚úÇÔ∏è Text truncated to fit timing");
        
        // ‚úÖ ADAPTIVE SPEAKING RATE - moved to AFTER real duration measurement
        
        // Generuj audio pro tento segment
        const voiceResponse = await generateVoice(
          textToSpeak,
          apiKeys.voiceId,
          apiKeys.elevenlabs,
          voiceSettings
        );

        // ‚úÖ Validace ElevenLabs response
        if (!voiceResponse || !voiceResponse.audio_data) {
          throw new Error(`‚ùå ElevenLabs generation failed for segment ${i + 1}`);
        }

        // Ulo≈æ segment audio
        const timestamp = Date.now();
        const segmentFileName = `voice_segment_${i + 1}_${timestamp}.mp3`;
        const segmentAudioPath = await saveAudioFile(voiceResponse.audio_data, segmentFileName);
        
        // ‚úÖ Mƒö≈òEN√ç SKUTEƒåN√â D√âLKY AUDIO SOUBORU m√≠sto theoretical calculation
        const actualAudioPath = path.join(process.cwd(), 'public', segmentAudioPath.replace(/^\//, ''));
        const ffprobeCommand = `ffprobe -v quiet -show_entries format=duration -of csv=p=0 "${actualAudioPath}"`;
        const { stdout } = await execAsync(ffprobeCommand);
        const segmentDuration = parseFloat(stdout.trim());
        
        console.log(`üéµ Segment ${i + 1} REAL duration: ${segmentDuration.toFixed(3)}s (estimated was ${estimateDuration(textToSpeak, voiceSettings.speaking_rate).toFixed(1)}s)`);
        console.log(`‚è±Ô∏è Real ElevenLabs duration: ${segmentDuration.toFixed(2)}s`);
        
        // üìè KALIBRAƒåN√ç KROK - Po prvn√≠m segmentu dopoƒç√≠t√°me re√°lnou rychlost ElevenLabs
        if (i === 0) {
          const segmentWords = textToSpeak.split(/\s+/).length;
          const realWPS = segmentWords / segmentDuration;
          const expectedWPS = 3.5 * voiceSettings.speaking_rate;
          const correctionFactor = realWPS / expectedWPS;
          
          console.log(`üìè CALIBRATION STEP after segment 1:`);
          console.log(`   ‚Üí realWPS: ${realWPS.toFixed(2)} wps`);
          console.log(`   ‚Üí expectedWPS: ${expectedWPS.toFixed(2)} wps`);
          console.log(`   ‚Üí correctionFactor: ${correctionFactor.toFixed(2)}`);
          
          // Aplikuj korekci na glob√°ln√≠ estimation pro dal≈°√≠ segmenty
          // Pozn√°mka: Toto ovlivn√≠ estimation pro truncation controls
        }
        
        generatedSegments.push({
          id: segment.id || `segment_${i + 1}`,
          text: textToSpeak,
          audioFilePath: segmentAudioPath,
          startTime: currentTime,
          endTime: currentTime + segmentDuration,
          duration: segmentDuration
        });
        
        currentTime += segmentDuration;
        console.log(`‚úÖ Segment ${i + 1} ulo≈æen: ${segmentAudioPath} (${segmentDuration.toFixed(1)}s)`);
        
        // üéØ SPEAKING RATE ADAPTACE - kdy≈æ je ElevenLabs rychlej≈°√≠ ne≈æ oƒçek√°v√°no
        const expectedSegmentDuration = estimateDuration(textToSpeak, voiceSettings.speaking_rate);
        if (segmentDuration < expectedSegmentDuration * 0.8) {
          console.warn(`‚ö†Ô∏è ElevenLabs too fast: ${segmentDuration.toFixed(2)}s vs expected ${expectedSegmentDuration.toFixed(2)}s ‚Üí slowing down`);
          voiceSettings.speaking_rate *= 0.75; // zpomal√≠ o 25%
          voiceSettings.speaking_rate = Math.max(voiceSettings.speaking_rate, 0.6); // min limit
          console.log(`üêå Adjusted speaking_rate to: ${voiceSettings.speaking_rate.toFixed(2)}`);
        }
        
        // ‚úÖ GLOBAL DURATION CONTROL - aggressive approach
        if (i < timelineSegments.length - 1) { 
          const accumulatedRealDuration = generatedSegments.reduce((sum, seg) => sum + seg.duration, 0);
          const remainingTargetTime = targetDuration - accumulatedRealDuration;
          const remainingSegments = timelineSegments.length - (i + 1);
          
          console.log(`üéØ GLOBAL CONTROL: After segment ${i + 1}: accumulated ${accumulatedRealDuration.toFixed(2)}s, remaining ${remainingTargetTime.toFixed(2)}s for ${remainingSegments} segments`);
          
          if (remainingSegments > 0) {
            const avgTimePerRemainingSegment = remainingTargetTime / remainingSegments;
            
            if (avgTimePerRemainingSegment < 2.0) {
              // Velmi m√°lo ƒçasu zb√Ωv√° ‚Üí agresivn√≠ truncation a vysok√Ω speaking rate
              console.warn(`üö® EMERGENCY: Only ${avgTimePerRemainingSegment.toFixed(1)}s per remaining segment! Applying emergency controls.`);
              
              // Truncate remaining segments heavily
              const maxWordsPerRemainingSegment = Math.floor(avgTimePerRemainingSegment * 2.3 * 1.8); // Allow 1.8 speaking rate
              console.log(`‚úÇÔ∏è EMERGENCY TRUNCATION: Max ${maxWordsPerRemainingSegment} words per remaining segment`);
              
              // Aggressive speaking rate
              voiceSettings.speaking_rate = Math.min(1.8, avgTimePerRemainingSegment > 1.5 ? 1.5 : 1.8);
            } else if (avgTimePerRemainingSegment < 3.0) {
              // Moderate time pressure ‚Üí moderate adjustments
              voiceSettings.speaking_rate = Math.min(1.5, 1.2);
              console.log(`‚ö° MODERATE ADJUSTMENT: ${avgTimePerRemainingSegment.toFixed(1)}s/segment ‚Üí rate ${voiceSettings.speaking_rate}`);
            } else {
              // Plenty of time ‚Üí slow down for quality
              voiceSettings.speaking_rate = Math.max(0.9, 1.0);
              console.log(`üêå SLOW DOWN: ${avgTimePerRemainingSegment.toFixed(1)}s/segment ‚Üí rate ${voiceSettings.speaking_rate}`);
            }
          }
        }
        
      } catch (segmentError) {
        console.error(`‚ùå Chyba p≈ôi generov√°n√≠ segmentu ${i + 1}:`, segmentError);
        throw new Error(`Generov√°n√≠ segmentu ${i + 1} selhalo: ${segmentError.message}`);
      }
    }

    const totalGeneratedDuration = generatedSegments.reduce((sum, seg) => sum + seg.duration, 0);
    
    // üü† DEBUG: ElevenLabs API responded...
    console.log("üü† DEBUG: ElevenLabs API responded...");
    console.log(`Expected audio segments: ${timelineSegments.length}`);
    console.log(`Returned audio segments: ${generatedSegments.length}`);
    generatedSegments.forEach((resp, i) => {
      console.log(`Audio #${i+1}: file=${resp.audioFilePath}, duration=${resp.duration?.toFixed(2) || 'unknown'}s`);
    });

    // Pokud ElevenLabs vr√°t√≠ m√©nƒõ segment≈Ø, stopni pipeline:
    if (generatedSegments.length !== timelineSegments.length) {
      throw new Error(`‚ùå CRITICAL: ElevenLabs returned ${generatedSegments.length} audios but expected ${timelineSegments.length}`);
    }
    
    console.log(`üéâ Voice Generation dokonƒçen! ${generatedSegments.length} segment≈Ø, celkov√° d√©lka: ${totalGeneratedDuration.toFixed(1)}s`);

    // üé¨ SLUƒåOV√ÅN√ç SEGMENT≈Æ DO FIN√ÅLN√çHO AUDIO
    let finalAudioPath: string | undefined;
    let finalAudioDuration: number | undefined;
    
    console.log('üîç MERGE DEBUG - pipelineId:', pipelineId);
    console.log('üîç MERGE DEBUG - generatedSegments.length:', generatedSegments.length);
    console.log('üîç MERGE DEBUG - targetDuration:', targetDuration);
    
    if (pipelineId && generatedSegments.length > 0) {
      try {
        console.log('üé¨ Sluƒçuji audio segmenty do fin√°ln√≠ho souboru...');
        finalAudioPath = await mergeAudioSegments(generatedSegments, pipelineId, targetDuration);
        
        // Ovƒõ≈ô d√©lku fin√°ln√≠ho audio pomoc√≠ ffprobe
        const finalFilePath = path.join(process.cwd(), 'public', finalAudioPath);
        const ffprobeCommand = `ffprobe -v quiet -show_entries format=duration -of csv=p=0 "${finalFilePath}"`;
        const { stdout } = await execAsync(ffprobeCommand);
        finalAudioDuration = parseFloat(stdout.trim());
        
        console.log(`‚úÖ Fin√°ln√≠ audio vytvo≈ôeno: ${finalAudioPath} (${finalAudioDuration.toFixed(2)}s)`);
        console.log(`üîç Final ElevenLabs audio: ${finalAudioDuration.toFixed(2)}s vs target ${targetDuration.toFixed(2)}s`);
        
        // ‚úÖ Post-generation truncation (pokud je audio del≈°√≠ ne≈æ target)
        if (finalAudioDuration > targetDuration + 0.3) { // 300ms tolerance
          console.warn(`‚úÇÔ∏è ElevenLabs audio je del≈°√≠ (${finalAudioDuration.toFixed(2)}s) ‚Üí o≈ôez√°v√°m na ${targetDuration}s`);
          const truncatedPath = finalAudioPath.replace('.mp3', '_truncated.mp3');
          const truncatedFullPath = path.join(process.cwd(), 'public', truncatedPath);
          const truncateCommand = `ffmpeg -i "${finalFilePath}" -t ${targetDuration} -c copy -y "${truncatedFullPath}"`;
          
          try {
            await execAsync(truncateCommand);
            // Zmƒõ≈à fin√°ln√≠ soubor na o≈ôezan√Ω
            const moveCommand = `mv "${truncatedFullPath}" "${finalFilePath}"`;
            await execAsync(moveCommand);
            finalAudioDuration = targetDuration; // Aktualizuj d√©lku
            console.log(`‚úÖ Audio √∫spƒõ≈°nƒõ o≈ôez√°no na ${targetDuration}s`);
          } catch (truncateError) {
            console.error('‚ùå Chyba p≈ôi o≈ôez√°v√°n√≠ audio:', truncateError);
          }
        } else {
          console.log(`‚úÖ ElevenLabs audio je v toleranci (${finalAudioDuration.toFixed(2)}s), nech√°v√°m beze zmƒõny`);
        }
        
        // Validace d√©lky fin√°ln√≠ho audio
        if (finalAudioDuration < targetDuration - 0.5) {
          console.warn(`‚ö†Ô∏è Fin√°ln√≠ audio je krat≈°√≠ ne≈æ target: ${finalAudioDuration.toFixed(2)}s < ${targetDuration}s`);
        }
        
      } catch (mergeError) {
        console.error('‚ùå Chyba p≈ôi sluƒçov√°n√≠ segment≈Ø:', mergeError);
        // Pokraƒçuj bez fin√°ln√≠ho audio - fallback na segmenty
        console.log('üìã Fallback: pou≈æ√≠v√°m individu√°ln√≠ segmenty m√≠sto fin√°ln√≠ho audio');
      }
    }

    // ‚úÖ Enhanced result s kompletn√≠mi metadaty
    const result: VoiceGenerationResult = {
      segments: generatedSegments,
      totalDuration: totalGeneratedDuration,
      targetTime: targetDuration,
      speakingRate: speakingRate,
      finalAudioPath,
      finalAudioDuration
    };
    
    // ‚úÖ Final summary log
    console.log('üéâ VOICE GENERATION SUMMARY:');
    console.log(`   üìä Generated segments: ${generatedSegments.length}`);
    console.log(`   ‚è±Ô∏è Individual segments total: ${totalGeneratedDuration.toFixed(2)}s`);
    console.log(`   üéØ Target duration: ${targetDuration}s`);
    console.log(`   üéöÔ∏è Speaking rate used: ${speakingRate}`);
    console.log(`   üéµ Final audio: ${finalAudioPath ? 'merged' : 'individual segments'}`);
    console.log(`   üìè Final duration: ${finalAudioDuration ? finalAudioDuration.toFixed(2) + 's' : 'N/A'}`);
    
    return result;

  } catch (error) {
    console.error('‚ùå Voice Generation chyba:', error);
    throw new Error(`Voice Generation selhal: ${error.message}`);
  }
} 